{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e65271-c06b-45c9-80f4-86d895b83b4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RetryCallState' from 'tenacity' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/webscrape/lib/python3.9/site-packages/langchain/chains/__init__.py:92\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/webscrape/lib/python3.9/site-packages/langchain/_api/module_import.py:69\u001b[0m, in \u001b[0;36mcreate_importer.<locals>.import_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImporting from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllowed top-level packages are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWED_TOP_LEVEL_PKGS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m     )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_module\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain_community\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/webscrape/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/webscrape/lib/python3.9/site-packages/langchain/chains/llm.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Sequence, Tuple, Union, cast\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     AsyncCallbackManager,\n\u001b[1;32m     10\u001b[0m     AsyncCallbackManagerForChainRun,\n\u001b[1;32m     11\u001b[0m     CallbackManager,\n\u001b[1;32m     12\u001b[0m     CallbackManagerForChainRun,\n\u001b[1;32m     13\u001b[0m     Callbacks,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     BaseLanguageModel,\n\u001b[1;32m     17\u001b[0m     LanguageModelInput,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdump\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dumpd\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/webscrape/lib/python3.9/site-packages/langchain_core/callbacks/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Callback handlers** allow listening to events in LangChain.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m**Class hierarchy:**\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    BaseCallbackHandler --> <name>CallbackHandler  # Example: AimCallbackHandler\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     AsyncCallbackHandler,\n\u001b[1;32m     11\u001b[0m     BaseCallbackHandler,\n\u001b[1;32m     12\u001b[0m     BaseCallbackManager,\n\u001b[1;32m     13\u001b[0m     CallbackManagerMixin,\n\u001b[1;32m     14\u001b[0m     Callbacks,\n\u001b[1;32m     15\u001b[0m     ChainManagerMixin,\n\u001b[1;32m     16\u001b[0m     LLMManagerMixin,\n\u001b[1;32m     17\u001b[0m     RetrieverManagerMixin,\n\u001b[1;32m     18\u001b[0m     RunManagerMixin,\n\u001b[1;32m     19\u001b[0m     ToolManagerMixin,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileCallbackHandler\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     AsyncCallbackManager,\n\u001b[1;32m     24\u001b[0m     AsyncCallbackManagerForChainGroup,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     RunManager,\n\u001b[1;32m     40\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/webscrape/lib/python3.9/site-packages/langchain_core/callbacks/base.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Dict, List, Optional, Sequence, TypeVar, Union\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UUID\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtenacity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetryCallState\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgentAction, AgentFinish\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'RetryCallState' from 'tenacity' (unknown location)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Initialize the language model\n",
    "llm = OpenAI(openai_api_key=\"sk-proj-3fVUL0QHqKKi5Z4FWrVAT3BlbkFJBL5WCAAlNRjmpJumj056\")\n",
    "\n",
    "# Define a prompt template for extracting information\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"html_content\"],\n",
    "    template=\"\"\"\n",
    "    Extract the following information from the HTML content:\n",
    "    - name (e.g: 200 Degrees Coffee Roastery)\n",
    "    - first wave (e.g: 1, 2 ,3, NA)\n",
    "    - coffees (e.g: 8, 5 ,10)\n",
    "    - city (e.g: NOTTINGHAM)\n",
    "    - country (e.g United Kingdom)\n",
    "    - shop_site (e.g: https://200degs.com/collections/coffee-beans/)\n",
    "    - google_rating (e.g:4.9)\n",
    "    - google_reviews (e.g:22)\n",
    "    - website (e.g: https://200degs.com)\n",
    "    - facebook (e.g: https://www.facebook.com/200DegreesCoffee)\n",
    "    - instagram (e.g: https://www.instagram.com/200degs/)\n",
    "    - latitude (e.g: 53)\n",
    "    - longitude (e.g: -1)\n",
    "\n",
    "    HTML: {html_content}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Function to scrape website content\n",
    "def scrape_website(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to preprocess HTML content\n",
    "def preprocess_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    # Extract relevant parts of the HTML\n",
    "    main_content = soup.get_text(separator=\"\\n\")\n",
    "    # Optionally, you can perform more specific extraction and cleaning here\n",
    "    return main_content\n",
    "\n",
    "# Function to extract information using LangChain\n",
    "def extract_information(html_content):\n",
    "    preprocessed_content = preprocess_html(html_content)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    try:\n",
    "        result = chain.run({\"html_content\": preprocessed_content})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Failed to extract information.\"\n",
    "\n",
    "# Example usage\n",
    "url = \"https://europeancoffeetrip.com/roaster/3fe/\"\n",
    "html_content = scrape_website(url)\n",
    "if html_content:\n",
    "    extracted_info = extract_information(html_content)\n",
    "    print(extracted_info)\n",
    "else:\n",
    "    print(\"Failed to retrieve website content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106604fc-77d8-46ff-aacd-456d1ffe6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import openai\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Initialize the OpenAI API key\n",
    "openai.api_key = \"sk-proj-3fVUL0QHqKKi5Z4FWrVAT3BlbkFJBL5WCAAlNRjmpJumj056\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eee2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "979dcbe8-4916-475b-aad5-1955a04daeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided HTML content, here's the extracted information:\n",
      "\n",
      "- name: 3fe\n",
      "- city: Dublin\n",
      "- country: Ireland\n",
      "- address: 7 Sussex Terrace, D04 A8N4, Dublin, Ireland\n",
      "\n",
      "Unfortunately, the HTML content does not provide information about the first wave, coffees, shop_site, google_rating, google_reviews, website, facebook, instagram, latitude, and longitude.\n"
     ]
    }
   ],
   "source": [
    "# Function to scrape website content\n",
    "def scrape_website(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to preprocess HTML content\n",
    "def preprocess_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    main_content = soup.get_text(separator=\"\\n\")\n",
    "    return main_content\n",
    "\n",
    "# Define the initial prompt template\n",
    "initial_prompt = \"\"\"\n",
    "    Extract the following information from the HTML content:\n",
    "    - name (e.g: 200 Degrees Coffee Roastery)\n",
    "    - first wave (e.g: 1, 2 ,3, NA)\n",
    "    - coffees (e.g: 8, 5 ,10)\n",
    "    - city (e.g: NOTTINGHAM)\n",
    "    - country (e.g United Kingdom)\n",
    "    - shop_site (e.g: https://200degs.com/collections/coffee-beans/)\n",
    "    - google_rating (e.g:4.9)\n",
    "    - google_reviews (e.g:22)\n",
    "    - website (e.g: https://200degs.com)\n",
    "    - facebook (e.g: https://www.facebook.com/200DegreesCoffee)\n",
    "    - instagram (e.g: https://www.instagram.com/200degs/)\n",
    "    - latitude (e.g: 53)\n",
    "    - longitude (e.g: -1)\n",
    "\n",
    "    HTML: {html_content}\n",
    "    \"\"\"\n",
    "\n",
    "# Function to extract information using OpenAI's chat.completions.create\n",
    "def extract_information(html_content):\n",
    "    preprocessed_content = preprocess_html(html_content)\n",
    "    prompt = initial_prompt.format(html_content=preprocessed_content)\n",
    "    \n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=2048,\n",
    "        temperature=0.5,\n",
    "        top_p=1\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://europeancoffeetrip.com/roaster/3fe/\"\n",
    "    html_content = scrape_website(url)\n",
    "    if html_content:\n",
    "        extracted_info = extract_information(html_content)\n",
    "        print(extracted_info)\n",
    "    else:\n",
    "        print(\"Failed to retrieve website content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ce04857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Roaster: Wood Grouse Coffee Roasters\n",
      "- Brand: Wood Grouse Coffee\n",
      "- Country: Ethiopia\n",
      "- Price: from €12.60\n",
      "- Currency: Euro (€)\n",
      "- Bagsize: 250g, 500g, 1000g\n",
      "- Units: g (grams)\n",
      "- Grower Named: Yes (Israel Degfa)\n",
      "- Grower Type: Private owner\n",
      "- F_R_O_N: Not provided in the given HTML content\n",
      "- Cup Score: 88\n",
      "- Date: Not provided in the given HTML content\n"
     ]
    }
   ],
   "source": [
    "url = \"https://woodgrousecoffee.com/shop/ana-sora-microlot\"\n",
    "html_content = scrape_website(url)\n",
    "if html_content:\n",
    "    extracted_info = extract_information(html_content)\n",
    "    print(extracted_info)\n",
    "else:\n",
    "    print(\"Failed to retrieve website content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b849f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Roaster: Workshop Coffee\n",
      "- Brand: La Plata Decaf\n",
      "- Country: Colombia\n",
      "- Price: £14.00, £28.00, £50.00 (depending on the bag size)\n",
      "- Currency: GBP\n",
      "- Bagsize: 250g, 500g, 1kg\n",
      "- Units: Not specified\n",
      "- Grower Named: Yes (Producers such as Gina Samara Jalvin, Gloria Isabel Garcia, Ivonne Andrea Oviedo and Laura Ramirez)\n",
      "- Grower Type: Not specified\n",
      "- F_R_O_N: Not specified\n",
      "- Cup Score: Not specified\n",
      "- Date: Not specified\n"
     ]
    }
   ],
   "source": [
    "url = \"https://workshopcoffee.com/products/la-pllata-decaf\"\n",
    "html_content = scrape_website(url)\n",
    "if html_content:\n",
    "    extracted_info = extract_information(html_content)\n",
    "    print(extracted_info)\n",
    "else:\n",
    "    print(\"Failed to retrieve website content.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
